@article{mittalsurvey2017,
	title = {A survey of techniques for architecting {TLBs}},
	volume = {29},
	rights = {Copyright © 2016 John Wiley \& Sons, Ltd.},
	issn = {1532-0634},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.4061},
	doi = {10.1002/cpe.4061},
	abstract = {Translation lookaside buffer ({TLB}) caches virtual to physical address translation information and is used in systems ranging from embedded devices to high-end servers. Because {TLB} is accessed very frequently and a {TLB} miss is extremely costly, prudent management of {TLB} is important for improving performance and energy efficiency of processors. In this paper, we present a survey of techniques for architecting and managing {TLBs}. We characterize the techniques across several dimensions to highlight their similarities and distinctions. We believe that this paper will be useful for chip designers, computer architects, and system engineers.},
	pages = {e4061},
	number = {10},
	journaltitle = {Concurrency and Computation: Practice and Experience},
	author = {Mittal, Sparsh},
	urldate = {2024-06-24},
	date = {2017},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.4061},
	keywords = {classification, power management, prefetching, Review, superpage, {TLB}, virtual cache, workload characterization},
	file = {Snapshot:/Users/akilan/Zotero/storage/JJ9H6B2H/cpe.html:text/html},
}

@article{woodruffcheri2019,
	title = {{CHERI} Concentrate: Practical Compressed Capabilities},
	volume = {68},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {0018-9340, 1557-9956, 2326-3814},
	url = {https://ieeexplore.ieee.org/document/8703061/},
	doi = {10.1109/TC.2019.2914037},
	shorttitle = {{CHERI} Concentrate},
	abstract = {We present {CHERI} Concentrate, a new fat-pointer compression scheme applied to {CHERI}, the most developed capability-pointer system at present. Capability fat pointers are a primary candidate to enforce ﬁne-grained and non-bypassable security properties in future computer systems, although increased pointer size can severely affect performance. Thus, several proposals for capability compression have been suggested elsewhere that do not support legacy instruction sets, ignore features critical to the existing software base, and also introduce design inefﬁciencies to {RISC}-style processor pipelines. {CHERI} Concentrate improves on the state-of-the-art region-encoding efﬁciency, solves important pipeline problems, and eases semantic restrictions of compressed encoding, allowing it to protect a full legacy software stack. We present the ﬁrst quantitative analysis of compiled capability code, which we use to guide the design of the encoding format. We analyze and extend logic from the open-source {CHERI} prototype processor design on {FPGA} to demonstrate encoding efﬁciency, minimize delay of pointer arithmetic, and eliminate additional load-to-use delay. To verify correctness of our proposed high-performance logic, we present a {HOL}4 machine-checked proof of the decode and pointer-modify operations. Finally, we measure a 50\% to 75\% reduction in L2 misses for many compiled C-language benchmarks running under a commodity operating system using compressed 128-bit and 64-bit formats, demonstrating both compatibility with and increased performance over the uncompressed, 256-bit format.},
	pages = {1455--1469},
	number = {10},
	journaltitle = {{IEEE} Transactions on Computers},
	shortjournal = {{IEEE} Trans. Comput.},
	author = {Woodruff, Jonathan and Joannou, Alexandre and Xia, Hongyan and Fox, Anthony and Norton, Robert M. and Chisnall, David and Davis, Brooks and Gudka, Khilan and Filardo, Nathaniel W. and Markettos, A. Theodore and Roe, Michael and Neumann, Peter G. and Watson, Robert N. M. and Moore, Simon W.},
	urldate = {2024-05-27},
	date = {2019-10-01},
	langid = {english},
	file = {Woodruff et al. - 2019 - CHERI Concentrate Practical Compressed Capabiliti.pdf:/Users/akilan/Zotero/storage/3SZUIWQ5/Woodruff et al. - 2019 - CHERI Concentrate Practical Compressed Capabiliti.pdf:application/pdf},
}

@article{bidpdk-based2016,
	title = {{DPDK}-based Improvement of Packet Forwarding},
	volume = {7},
	rights = {© Owned by the authors, published by {EDP} Sciences, 2016},
	issn = {2271-2097},
	url = {https://www.itm-conferences.org/articles/itmconf/abs/2016/02/itmconf_ita2016_01009/itmconf_ita2016_01009.html},
	doi = {10.1051/itmconf/20160701009},
	abstract = {Reel-time processing of packets occupies a significant position in the field of computer network security. With theexplosive growth of the backbone link rate,which is consistent with Gilder's law, many bottlenecks of server performance leave the real-time data stream unprocessed.Thus, we proposedto take use of {DPDK}(Data Plan Development Kit) framework to achieve an intelligent {NIC} packet forwarding system. During this research, we deeply analysis the forwarding process of packet in {DPDK} and improve its {DMA} mode.According to the results of experiment, the system greatly enhanced the performance of packet forwarding,and the throughput of forwarding 64-byet or random-length packets by 20Gbit {NIC} reaches13.3Gbps and 18.7Gbps(dual ports forwarding).},
	pages = {01009},
	journaltitle = {{ITM} Web of Conferences},
	shortjournal = {{ITM} Web Conf.},
	author = {Bi, Hao and Wang, Zhao-Hun},
	urldate = {2024-06-07},
	date = {2016},
	langid = {english},
	note = {Publisher: {EDP} Sciences},
	file = {Full Text PDF:/Users/akilan/Zotero/storage/LEVMJ983/Bi and Wang - 2016 - DPDK-based Improvement of Packet Forwarding.pdf:application/pdf},
}

@article{chenflexpointer2023,
	title = {{FlexPointer}: Fast Address Translation Based on Range {TLB} and Tagged Pointers},
	volume = {20},
	issn = {1544-3566, 1544-3973},
	url = {https://dl.acm.org/doi/10.1145/3579854},
	doi = {10.1145/3579854},
	shorttitle = {{FlexPointer}},
	abstract = {Page-based virtual memory relies on {TLBs} to accelerate the address translation. Nowadays, the gap between application workloads and the capacity of {TLB} continues to grow, bringing many costly {TLB} misses and making the {TLB} a performance bottleneck. Previous studies seek to narrow the gap by exploiting the contiguity of physical pages. One promising solution is to group pages that are both virtually and physically contiguous into a memory range. Recording range translations can greatly increase the {TLB} reach, but ranges are also hard to index because they have arbitrary bounds. The processor has to compare against all the boundaries to determine which range an address falls in, which restricts the usage of memory ranges.
            In this article, we propose a tagged-pointer-based scheme, {FlexPointer}, to solve the range indexing problem. The core insight of {FlexPointer} is that large memory objects are rare, so we can create memory ranges based on such objects and assign each of them a unique {ID}. With the range {ID} integrated into pointers, we can index the range {TLB} with {IDs} and greatly simplify its structure. Moreover, because the {ID} is stored in the unused bits of a pointer and is not manipulated by the address generation, we can shift the range lookup to an earlier stage, working in parallel with the address generation. According to our trace-based simulation results, {FlexPointer} can reduce nearly all the L1 {TLB} misses, and page walks for a variety of memory-intensive workloads. Compared with a 4K-page baseline system, {FlexPointer} shows a 14\% performance improvement on average and up to 2.8x speedup in the best case. For other workloads, {FlexPointer} shows no performance degradation.},
	pages = {1--24},
	number = {2},
	journaltitle = {{ACM} Transactions on Architecture and Code Optimization},
	shortjournal = {{ACM} Trans. Archit. Code Optim.},
	author = {Chen, Dongwei and Tong, Dong and Yang, Chun and Yi, Jiangfang and Cheng, Xu},
	urldate = {2024-05-27},
	date = {2023-06-30},
	langid = {english},
	file = {Full Text PDF:/Users/akilan/Zotero/storage/L9XGZDFK/Chen et al. - 2023 - FlexPointer Fast Address Translation Based on Ran.pdf:application/pdf},
}

@inproceedings{panwarhawkeye2019,
	location = {Providence {RI} {USA}},
	title = {{HawkEye}: Efficient Fine-grained {OS} Support for Huge Pages},
	isbn = {978-1-4503-6240-5},
	url = {https://dl.acm.org/doi/10.1145/3297858.3304064},
	doi = {10.1145/3297858.3304064},
	shorttitle = {{HawkEye}},
	eventtitle = {{ASPLOS} '19: Architectural Support for Programming Languages and Operating Systems},
	pages = {347--360},
	booktitle = {Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems},
	publisher = {{ACM}},
	author = {Panwar, Ashish and Bansal, Sorav and Gopinath, K.},
	urldate = {2024-05-27},
	date = {2019-04-04},
	langid = {english},
	file = {Full Text PDF:/Users/akilan/Zotero/storage/VQLCKYCA/Panwar et al. - 2019 - HawkEye Efficient Fine-grained OS Support for Hug.pdf:application/pdf},
}

@inproceedings{karakostasredundant2015,
	location = {Portland Oregon},
	title = {Redundant memory mappings for fast access to large memories},
	isbn = {978-1-4503-3402-0},
	url = {https://dl.acm.org/doi/10.1145/2749469.2749471},
	doi = {10.1145/2749469.2749471},
	abstract = {Page-based virtual memory improves programmer productivity, security, and memory utilization, but incurs performance overheads due to costly page table walks after {TLB} misses. This overhead can reach 50\% for modern workloads that access increasingly vast memory with stagnating {TLB} sizes. To reduce the overhead of virtual memory, this paper proposes Redundant Memory Mappings ({RMM}), which leverage ranges of pages and provides an efﬁcient, alternative representation of many virtual-to-physical mappings. We deﬁne a range be a subset of process’s pages that are virtually and physically contiguous. {RMM} translates each range with a single range table entry, enabling a modest number of entries to translate most of the process’s address space. {RMM} operates in parallel with standard paging and uses a software range table and hardware range {TLB} with arbitrarily large reach. We modify the operating system to automatically detect ranges and to increase their likelihood with eager page allocation. {RMM} is thus transparent to applications. We prototype {RMM} software in Linux and emulate the hardware. {RMM} performs substantially better than paging alone and huge pages, and improves a wider variety of workloads than direct segments (one range per program), reducing the overhead of virtual memory to less than 1\% on average.},
	eventtitle = {{ISCA} '15: The 42nd Annual International Symposium on Computer Architecture},
	pages = {66--78},
	booktitle = {Proceedings of the 42nd Annual International Symposium on Computer Architecture},
	publisher = {{ACM}},
	author = {Karakostas, Vasileios and Gandhi, Jayneel and Ayar, Furkan and Cristal, Adrián and Hill, Mark D. and {McKinley}, Kathryn S. and Nemirovsky, Mario and Swift, Michael M. and Ünsal, Osman},
	urldate = {2024-05-27},
	date = {2015-06-13},
	langid = {english},
	file = {Karakostas et al. - 2015 - Redundant memory mappings for fast access to large.pdf:/Users/akilan/Zotero/storage/8JECES24/Karakostas et al. - 2015 - Redundant memory mappings for fast access to large.pdf:application/pdf},
}

@article{esswoodcheriosnodate,
	title = {{CheriOS}: designing an untrusted single-address-space capability operating system utilising capability hardware and a minimal hypervisor},
	author = {Esswood, Lawrence G},
	langid = {english},
	file = {Esswood - CheriOS designing an untrusted single-address-spa.pdf:/Users/akilan/Zotero/storage/YGIBFTD5/Esswood - CheriOS designing an untrusted single-address-spa.pdf:application/pdf},
}