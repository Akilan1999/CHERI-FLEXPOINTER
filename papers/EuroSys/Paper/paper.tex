%%
%% This is file `sample-sigconf-authordraft.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,authordraft')
%%
%% IMPORTANT NOTICE:
%%
%% For the copyright see the source file.
%%
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf-authordraft.tex.
%%
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%%
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigconf,authordraft]{acmart}
\usepackage{listings}
\lstset{basicstyle=\small\ttfamily,columns=fullflexible}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation emai}{June 03--05,
  2018}{Woodstock, NY}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{FAT Pointer based range addresses}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Akilan Selvacoumar}
% \authornote{Both authors contributed equally to this research.}
% \email{as251@hw.ac.uk}
% \orcid{1234-5678-9012}
% \author{G.K.M. Tobin}
\authornotemark[1]
\email{as251@hw.ac.uk}
\affiliation{%
  \institution{Heriot Watt}
  \city{Edinburgh}
  \state{Scotland}
  \country{United Kingdom}
}

% \author{Lars Th{\o}rv{\"a}ld}
% \affiliation{%
%   \institution{The Th{\o}rv{\"a}ld Group}
%   \city{Hekla}
%   \country{Iceland}}
% \email{larst@affiliation.org}

% \author{Valerie B\'eranger}
% \affiliation{%
%   \institution{Inria Paris-Rocquencourt}
%   \city{Rocquencourt}
%   \country{France}
% }

% \author{Aparna Patel}
% \affiliation{%
%  \institution{Rajiv Gandhi University}
%  \city{Doimukh}
%  \state{Arunachal Pradesh}
%  \country{India}}

% \author{Huifen Chan}
% \affiliation{%
%   \institution{Tsinghua University}
%   \city{Haidian Qu}
%   \state{Beijing Shi}
%   \country{China}}

% \author{Charles Palmer}
% \affiliation{%
%   \institution{Palmer Research Laboratories}
%   \city{San Antonio}
%   \state{Texas}
%   \country{USA}}
% \email{cpalmer@prl.com}

% \author{John Smith}
% \affiliation{%
%   \institution{The Th{\o}rv{\"a}ld Group}
%   \city{Hekla}
%   \country{Iceland}}
% \email{jsmith@affiliation.org}

% \author{Julius P. Kumquat}
% \affiliation{%
%   \institution{The Kumquat Consortium}
%   \city{New York}
%   \country{USA}}
% \email{jpkumquat@consortium.net}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
% \renewcommand{\shortauthors}{Trovato et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
The increasing disparity between application workloads and the capacity of Translation Lookaside Buffers (TLB) 
has prompted researchers to explore innovative solutions to mitigate this gap. One such approach involves 
leveraging physically contiguous memory to optimize TLB utilization. Concurrently, advancements in hardware-level 
system security, exemplified by the Capability Hardware Enhanced RISC Instructions (CHERI) architecture, offer 
additional opportunities for improving memory management and security.
  
CHERI introduces capability-based addressing, a novel approach that enhances system security by associating capabilities 
with memory pointers. These capabilities restrict access to memory regions, thereby fortifying the system against various 
security threats. Importantly, the mechanisms implemented in CHERI for enforcing memory protection can also serve as 
accelerators for standard user-space memory allocators. By leveraging capability-based addressing, memory 
allocators can efficiently manage memory resources while ensuring robust security measures are in place.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
% %%
% \begin{CCSXML}
% <ccs2012>
%  <concept>
%   <concept_id>00000000.0000000.0000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>500</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>00000000.00000000.00000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>300</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>00000000.00000000.00000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>00000000.00000000.00000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
% </ccs2012>
% \end{CCSXML}

% \ccsdesc[500]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc[300]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc[100]{Do Not Use This Code~Generate the Correct Terms for Your Paper}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
% \keywords{Do, Not, Us, This, Code, Put, the, Correct, Terms, for,
%   Your, Paper}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
% \begin{teaserfigure}
%   \includegraphics[width=\textwidth]{sampleteaser}
%   \caption{Seattle Mariners at Spring Training, 2010.}
%   \Description{Enjoying the baseball game from the third-base
%   seats. Ichiro Suzuki preparing to bat.}
%   \label{fig:teaser}
% \end{teaserfigure}

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
In the dynamic landscape of computing, the pursuit of optimal performance is a constant endeavor, 
especially as applications evolve to handle increasingly complex workloads. 
One critical aspect influencing performance is memory management, where efficient 
utilization of resources is paramount. Translation Lookaside Buffers (TLBs) play a 
pivotal role in this regard, expediting memory access by storing recently accessed memory translations.
However, as applications grow in size and complexity, the capacity of TLBs often struggles to 
keep pace, leading to performance bottlenecks\cite{mittal_survey_2017}. To address this challenge, researchers have 
turned to innovative solutions, one of which involves harnessing the benefits of huge pages.
Huge pages, also known as large pages, allow for the allocation of memory in significantly 
larger chunks compared to traditional small pages. By reducing the number of TLB entries 
needed to access a given amount of memory, huge pages offer a potential avenue for optimizing 
TLB utilization and thereby enhancing overall system performance.

Simultaneously, advancements in hardware-level security, such as the Capability Hardware 
Enhanced RISC Instructions (CHERI) architecture, present additional opportunities for 
performance enhancement. CHERI's capability-based addressing approach not only strengthens 
system security by tightly controlling memory access but also provides avenues for 
accelerating memory management operations.

In this context, the integration of huge pages into memory management 
strategies alongside capability-based addressing in architectures like 
CHERI offers a compelling synergy. By optimizing TLB utilization through the 
utilization of huge pages and leveraging the security features of capability-based addressing, 
significant performance improvements can be realized. This approach not only enhances 
system security but also accelerates memory access. The following below are research questions 
we are addressing:
\newline

\begin{enumerate}
    \item How does the utilization of bounds for tracking memory allocations, in addition to security purposes, affect the 
    run times and Translation Lookaside Buffer (TLB) miss rates in modern computing systems?
    \item How does the implementation of bounds for seeking through physically contiguous memory influence the complexity and 
    efficiency of standard memory allocators, particularly those with advanced features such as transparent 
    huge pages, and what are the implications for system performance in terms of execution speed, memory access 
    latency, and resource utilization?
\end{enumerate}

\section{FAT Pointer based range addresses}
FAT-Pointers based range addresses, combined with the capabilities of the CHERI (Capability Hardware Enhanced RISC Instructions) 
architecture, introduce robust memory safety and security features by incorporating additional metadata 
with memory pointers. This enhanced architecture utilizes concepts such as FlexPointer, 
Range Memory Mapping (RMM) to manage memory effectively.

Range addresses play a pivotal role within this framework, defining memory 
regions bounded by a starting address (Upper) and an ending address (Lower). 
These range addresses are encoded within FAT-pointers, allowing for precise 
control over memory regions.

The functionality of ranges encompasses several key aspects:
\begin{itemize}
\item \textbf{Creation of Physically Contiguous Memory Ranges}:
By defining memory regions that are physically contiguous, systems can 
achieve optimal memory access patterns, enhancing performance and efficiency.
\item \textbf{Encoding Ranges as Bounds to the Pointer}:
Integrating range bounds directly into FAT-pointers enables the architecture 
to enforce memory access restrictions at the pointer level thus allowing 
tracking of memory ranges on a pointer level.
\item \textbf{Instrumenting Block-Based Allocators with Physically Contiguous Memory}:
The integration of range-based memory concepts into memory allocation systems, such as block-based 
allocators, facilitates the efficient management and utilization of physically contiguous memory blocks, 
mitigating issues related to memory fragmentation.
\end{itemize}

\begin{figure}[h]
  \includegraphics[width=0.4\textwidth]{diagram/HighOverviewArchitecture24.png}
  \caption{High overview architecture}
  \label{fig:HighOverviewArchitecture}
% \end{minipage}
\end{figure}

Figure \ref{fig:HighOverviewArchitecture} illustrates the methodology employed to leverage the CHERI 
128-bit FAT-pointer scheme for facilitating block-based memory management
on physically contiguous memory, which is depicted on the right side of the figure. 
This technique contrasts with the conventional mmap approach.

In figure \ref{fig:HighOverviewArchitecture}, the green-highlighted section marks the unused space between the 48th and 64th bits
within the FAT-pointer. This area of unused bits presents an opportunity to store additional metadata,
potentially enhancing the capabilities of the memory management system. 
Here we explore how this additional metadata storage could be used to further optimize memory allocation.

\subsection{Range creation and huge pages}
\begin{figure}[h]
  \includegraphics[width=0.4\textwidth]{diagram/AllocationOverview24.png}
  \caption{Range of memory}
  \label{fig:RangeOfMemory}
\end{figure}
In this implementation, memory ranges are established using bounds encoded within the FAT-pointer, adhering 
to the CHERI 128-bit bounds compression scheme\cite{woodruffcheri2019}. The memory chunk defined by the upper and lower bounds is 
always physically contiguous. Initially, a huge page of arbitrary size is allocated. Within this huge page, 
custom-sized memory segments are allocated using a custom-designed mmap function, which overrides the existing 
block-based mmap function. Once the memory is physically allocated through this custom mmap function, bounds 
are set to track the memory block, eliminating the need for traditional TLB usage for this purpose. Traditional TLB usage 
involves maintaining numerous TLB entries, often supplemented by an L2 TLB and other hierarchical structures, 
to translate virtual addresses to physical addresses. This approach requires multiple entries to handle various 
memory segments, leading to increased overhead and complexity in address translation. Conversely, 
the current approach streamlines this process by using a single TLB entry to translate multiple
addresses within a contiguous memory range. This reduces the number of required TLB entries, 
simplifying the translation process and improving efficiency. By consolidating address translations 
into a single TLB entry, this method minimizes the overhead associated with managing numerous TLB entries 
and leverages the bounds encoded within the FAT-pointer for efficient memory tracking and access. 
This approach allows for precise and efficient memory management within the allocated huge page. 

\smallskip\noindent
Figure \ref{fig:RangeOfMemory} illustrates a straightforward use-case in which the dark pink line represents a single, 
large contiguous memory area, or huge page. Within this huge page, the orange and blue lines indicate 
two separate memory allocations equivalent to invoking malloc twice to allocate memory in distinct regions. 
This scenario simulates a block-based memory allocator operating within the confines of the huge page. 
The allocations leverage the bounds encoded in the FAT-pointer, ensuring tracking and efficient 
management of the allocated memory regions. By using the FAT-pointer bounds, this method maintains the 
integrity and contiguity of the allocated blocks within the huge page.

\subsection{Software Stack}
The software stack is based on CHERIBSD, selected because ARM officially supports Morello's performance 
counters on this operating system. As illustrated in the figure \ref{fig:SoftwareStack}, the setup includes a C program that 
is linked to the prototype memory allocator or to various memory allocators being benchmarked. This linkage can occur in two ways: either as a shared object file during compile time 
for larger allocators, or as a header file for smaller allocators, ensuring flexibility and efficiency 
in memory management.
\newline

This integration ensures that the memory allocation process is optimized for performance, leveraging the contiguity 
of memory blocks and the capabilities provided by the CHERI architecture and the Morello platform. By using the 
contigmem driver and the custom mmap function, the system achieves efficient memory allocation and tracking, 
crucial for the high-performance needs of the application.

\subsection{Contigmem driver from DPDK}
The custom mmap function, tailored to ensure physically contiguous memory allocation, is a key component 
of this system. This function is linked to the contigmem driver, which has been modified from the DPDK\cite{bidpdk-based2016} library 
to meet the specific needs of this implementation. The contigmem driver is essential for managing large contiguous 
memory blocks and is loaded during the system boot process. It reserves a huge page of arbitrary size, with the 
size parameter set based on the requirements of the conducted experiments.

\begin{lstlisting}[language=C, caption=Contigmem driver , label=ContigInit]

  MALLOC_DEFINE(M_CONTIGMEM, "contigmem", 
  "contigmem(4) allocations");
  
  static int contigmem_modevent(module_t mod, 
  int type, void *arg)
  {
    int error = 0;
  
    switch (type) {
    case MOD_LOAD:
      error = contigmem_load();
      break;
    case MOD_UNLOAD:
      error = contigmem_unload();
      break;
    default:
      break;
    }
  
    return error;
  }

  ....

DECLARE_MODULE(contigmem, contigmem_mod, 
SI_SUB_DRIVERS, SI_ORDER_ANY);
MODULE_VERSION(contigmem, 1);

static struct cdevsw contigmem_ops = {
	.d_name         = "contigmem",
	.d_version      = D_VERSION,
	.d_flags        = D_TRACKCLOSE,
	.d_mmap_single  = contigmem_mmap_single,
	.d_open         = contigmem_open,
	.d_close        = contigmem_close,
};

static int
contigmem_load()
{
	....

	for (i = 0; i < contigmem_num_buffers; i++) {
		addr = contigmalloc(contigmem_buffer_size, 
           M_CONTIGMEM, M_ZERO,
		   0, BUS_SPACE_MAXADDR, 
           contigmem_buffer_size, 0);
	....
	}

    ....

error:
	for (i = 0; i < contigmem_num_buffers; i++) {
		if (contigmem_buffers[i].addr != NULL) {
			contigfree(contigmem_buffers[i].addr,
				contigmem_buffer_size, M_CONTIGMEM);
			contigmem_buffers[i].addr = NULL;
		}
		....
	}

	return error;
}

\end{lstlisting}

When the contigmem\_load function is called, either during boot or when the Kernel module is loaded, it pre-allocates 
a segment of physically contiguous memory. This approach differs from FlexPointer\cite{chenflexpointer2023}, 
which allocates physically contiguous memory eagerly. The contigmem\_load function allocates memory using contigmalloc, 
which allocates physically contiguous memory initialized to zero. The cdevsw struct refers to function 
calls which would be overwritten on loading the driver. In the code snippet above
the mmap function would be overwritten with contigmem\_mmap\_single if the following driver is opened and truncated
as shown in Code snippet. 
\newline

In the code snippet the cdev\_pager\_ops refers to the operations which will be overwritten 
when called with mmap such as overwriting page faults.

% \begin{lstlisting}[language=C, caption=Contigmem driver mmap , label=ContigMmap]

%   static struct cdev_pager_ops contigmem_cdev_pager_ops = {
%     .cdev_pg_ctor = contigmem_cdev_pager_ctor,
%     .cdev_pg_dtor = contigmem_cdev_pager_dtor,
%     .cdev_pg_fault = contigmem_cdev_pager_fault,
%   };
  
%   static int
%   contigmem_mmap_single(struct cdev *cdev, vm_ooffset_t 
%   *offset, vm_size_t size, struct vm_object **obj, int nprot)
%   {
%       ....
%     *obj = cdev_pager_allocate(vmh, OBJT_DEVICE, 
%              &contigmem_cdev_pager_ops,size, nprot, 
%              *offset, curthread->td_ucred);
  
%     return 0;
%   }
%   \end{lstlisting}

\subsubsection{Sample memory allocator design}

\begin{lstlisting}[linewidth=\columnwidth,breaklines=true,language=C, caption=Contigmem driver mmap , label=MallocSample]
  #define FILENAME "/dev/contigmem"
  void *ptr;
  int MallocCounter;

  size_t sizeUsed;
  
  ... 

  INITAlloc(void) {

  size_t sz;
  sz = 100000000;

  int fd = open(FILENAME, O_RDWR, 0600);

   if (fd < 0) {
       perror("open");
       exit(EXIT_FAILURE);
   }

   off_t offset = 0; // offset to seek to.

   if (ftruncate(fd, sz) < 0) {
       perror("ftruncate");
       close(fd);
       exit(EXIT_FAILURE);
   }

   ptr = mmap(NULL, sz,
   PROT_READ|PROT_WRITE, MAP_SHARED,fd,0);

  // Added error handling
   if(ptr == MAP_FAILED)
   {
       perror("mmap");
       exit(EXIT_FAILURE);
   }
   MallocCounter = (int)sz;
   }

   void* malloc(size_t sz)
   {
  sz = __builtin_align_up(sz, _Alignof(max_align_t));

  // printf("%d \n", sz);
  // printf("%d Malloc counter\n", MallocCounter);

  MallocCounter -= sz;
  void *ptrLink = &ptr[MallocCounter];
  ptrLink = cheri_setbounds(ptrLink, sz);

  return ptrLink;
    
  }

  void FREECHERI(void *ptr) { 

  // get length of free from bounds
  // in the pointer
  int len = cheri_getlen(ptr);

  munmap(ptr, len);
}

\end{lstlisting}

The code snippet.;
 below shows a sample memory allocator
which is a really simple implementation that initially 
in the example allocates 1GB of memory using the mmap call which calls 
the mmap function from /dev/contigmem driver. This ensures memory allocated to the physically
contiguous memory allocated in the contigmem\_load() function using the contigmem\_mmap\_single()
function call in the kernel module, uses malloc 
and free to allocate within this memory chuck. The consideration of this is to ensure that a C program needs minor changes to use the benefit
using physically contiguous memory with bounds within a segment of memory.

\section{Related work}
\subsection{Huge Pages}
% This is used to map a very large region of memory to a 
% single entry. This small/large region of memory is physically
% contiguous. Most implementations of huge pages \cite{panwar_hawkeye_2019} are size
% aligned, For example for the x86 architecture the huge pages 
% size are 4KB, 2MB and 1GB pages. 
Increasing TLB reach can be achieved by using larger page sizes, such as huge pages\cite{panwarhawkeye2019}, which are common in modern computer systems. 
The x86-64 architecture supports huge pages of 2 MB and 1 GB, backed by OS mechanisms like Transparent Huge Pages (THP) 
and HugeTLBFS in Linux. However, available page sizes in x86-64 are limited, leading to internal fragmentation issues. 
For instance, allocating 1 MB with 4 KB base pages requires 256 PTEs, but using a 2 MB huge page would waste 
half of the memory space. Some architectures offer more page size choices, such as Intel Itanium, which 
allows different areas of the address space to have their own page sizes. Itanium uses a hash page table to organize huge 
pages, but without significant changes to the conventional page table, it only helps reduce page walk overheads. 
HP Tunable Base Page Size permits the OS to adjust the base page size, but still faces internal fragmentation problems, 
with HP recommending a base page size of no more than 16 KB. Shadow Superpage introduces a new translation level 
in the memory controller to merge non-contiguous physical pages into a huge page in a shadow memory space, extending 
TLB coverage. However, this approach requires all memory traffic to be translated again in the memory controller, 
resulting in additional latency for memory accesses.

\subsection{Segment}
% A segment\cite{basu_efficient_nodate} can be viewed as mapping between contiguous virtual
% memory and contiguous physical memory. The property of a 
% segment allows it to be larger than a page. Direct Segment allows the user to set a single segment
% for an application. Two registers are added to mark the start
% and end of the segment. Any virtual address within this region
% can be translated by adding the fixed offset between the virtual
% and physical address.
Early processors often used segments to manage virtual memory, where a segment essentially mapped contiguous 
virtual memory to contiguous physical memory. Unlike pages, which are relatively small, segments can be much 
larger, offering the potential for more efficient memory management in certain scenarios. 
This concept of segmentation has seen a resurgence in some modern approaches that aim to enhance 
translation coverage by designating specific areas in the virtual address space.

% Alternate segment technique
% - JayneelGandhi,ArkapravaBasu,MarkD.Hill,andMichaelM.Swift.2014.Efficientmemoryvirtualization:Reducing
This method allows programmers to explicitly define 
a single segment for applications requiring significant memory. It introduces two new 
registers to the system, which indicate the start and end of this segment. 
Virtual addresses within this segment are translated by calculating 
the offset from the virtual start address and applying this offset to the 
physical start address. This straightforward method simplifies the translation 
process for large memory areas but requires significant modifications to the 
source code of applications.

\subsection{Range Memory Mapping (RMM):}
% RMM\cite{karakostas_redundant_2015} introduces the concept of adding an additional range table.
% For large allocations RMM eagerly allocates contiguous physical pages.
% The following allocations creates large memory ranges that are
% both virtually and physically contiguous. RMM builds on the concept
% of Direct segment by adding offset to translate a virtual address 
% to physical address. RMM compares address with range boundaries 
% to decide which range it belongs to. RMM queries the range table 
% ofter an L1 TLB miss.
Redundant Memory Mappings (RMM)\cite{karakostasredundant2015} enhance memory management by introducing an additional range table 
that pre-allocates contiguous physical pages for large memory allocations, creating ranges that 
are both virtually and physically contiguous. This approach simplifies address translation 
within these ranges by adding an offset, similar to Direct Segment, but RMM supports multiple 
ranges and operates transparently to programmers, requiring no source code modifications. 
The range table, separate from the conventional page table, holds the mappings for these 
large allocations. To determine which range an address belongs to, RMM compares the address 
against all range boundaries, a process that is computationally expensive and therefore performed 
only after an L1 TLB miss. To optimize this, RMM uses a range TLB (RTLB) to quickly identify 
if an address falls within any pre-allocated range, facilitating efficient translation and 
reducing overhead. Range mapping works alongside the paging system by generating TLB entries on 
TLB misses and still performing TLB lookups for each virtual address translation. 
Unlike traditional segmentation mechanisms, range mapping activates a range lookaside 
buffer (RTLB) located with the last level TLB upon a miss. The hardware TLB miss 
handler then searches the RTLB for the miss address and, if found, generates a new 
TLB entry with the physical address derived from the base virtual address and 
range offset, along with permission bits. If the RTLB also misses, the system 
defaults to a standard page walk while a range table walker simultaneously 
loads the range into the RTLB in the background, avoiding delays in memory operations. 
The RTLB, functioning as a fully associative search structure, ensures 
that most last level TLB misses are handled efficiently by range mapping, 
reducing the need for costly page table walks.



\subsection{CHERI}
CHERI (Capability Hardware Enhanced RISC Instructions) extends conventional processor
Instruction-Set Architectures (ISAs) with architectural capabilities to enable fine-grained
memory protection and highly scalable software compartmentalization. CHERI is a hybrid 
capability architecture that can combine capabilities with conventional MMU(i.e Memory Management
 Unit) based systems. The contribution of the following project include: 
\begin{itemize}
  \item ISA changes to introduce architecture capabilities.
  \item New microarchitecture proving that capabilities can be implemented efficiently 
        in hardware. Support for efficient tagged memory to protect capabilities and
        compress capabilities to reduce memory overhead.   
  \item Newly designed software construction model for that uses capability to provide
        fine grain memory protection and scalable software compartmentalization.  
  \item Language and Compiler extension to use capabilities for C and C++.
  \item OS extensions to use (and support application use of) fine-grained memory protection
        (spatial, referential, and (non-stack) temporal memory safety) and abstraction extensions
        to support scalable software compartmentalization. 
\end{itemize}

\subsection{Future work}
The current experimental setup on the ARM Morello board is constrained by the requirement that all memory reads must 
pass through the Translation Lookaside Buffer (TLB) for address translation. This necessitates frequent TLB lookups, potentially 
leading to performance bottlenecks. The planned future work aims to address this by leveraging CHERI 
(Capability Hardware Enhanced RISC Instructions) extensions on the RISC-V architecture, specifically using the 
Tooba implementation.

\subsubsection{Storing Offsets Directly on Pointers}
In the current ARM Morello setup, address translations rely on the TLB.
The future approach on RISC-V Tooba involves storing the offset directly within the pointer. This is possible due to CHERI's capability model, which supports fine-grained memory protection and can encode bounds within pointers.
Utilizing Bounds in CHERI for Block-Based Allocation:

CHERI capabilities allow pointers to carry metadata about memory bounds, providing hardware-enforced memory safety.
By encoding the offset and bounds within the pointer, the system can directly access memory without needing intermediate translations via the TLB.
This enables the implementation of a block-based allocator that can efficiently manage memory allocations and deallocations within defined bounds.
Bypassing the TLB in RISC-V Tooba.
\subsubsection{Hardware Modifications:}
The Bluespec design of the RISC-V processor will be modified to allow certain memory operations to bypass the TLB. This means that when a pointer with encoded offset and bounds is used, the system can directly compute the physical address from the capability information.
This modification reduces the dependency on the TLB, decreasing latency and improving performance, especially for frequent memory operations.
Transition to a Single-Address-Space Operating System (SASOS)\cite{esswoodcheriosnodate}.
\subsubsection{Concept of SASOS:}
In traditional operating systems, there is a clear separation between user space and kernel space. This separation is enforced by memory protection mechanisms and address translation through the TLB.
In a Single-Address-Space Operating System, this distinction is removed. Both user applications and the kernel share the same contiguous address space.
\subsubsection{Advantages of SASOS with CHERI:}
% Rewrite this bit
\begin{itemize}
  \item Simplified Memory Management : Without the need to switch between user and kernel spaces, memory management becomes simpler and more efficient.
The kernel allocator can be the same as the user space allocator, operating on a single, contiguous chunk of memory.
  \item Unified Allocator: The unified memory allocator can efficiently manage memory for both kernel and user applications, leveraging CHERI's capability-based protection to prevent unauthorized access.
This reduces overhead and potential fragmentation issues associated with maintaining separate memory spaces.
\end{itemize}

\section{Conclusion}  %Title of the Conclusion
This paper addresses the growing disparity between application workloads and the capacity of Translation Lookaside Buffers (TLBs). 
To mitigate this gap, it proposes leveraging physically contiguous memory to optimize TLB utilization. Additionally, 
the report explores advancements in system security, particularly through the Capability Hardware Enhanced RISC Instructions (CHERI) 
architecture. CHERI's capability-based addressing enhances system security by associating capabilities with memory pointers, 
restricting access to memory regions, and thus protecting against various security threats. Importantly, these mechanisms 
can also improve the efficiency of memory allocators by managing memory resources while ensuring robust security measures.
\newline

This paper highlights the constant pursuit of optimal performance in computing, emphasizing the importance of 
efficient memory management. TLBs are crucial in expediting memory access by storing recently accessed memory translations. 
However, as applications grow in size and complexity, TLB capacity often becomes a bottleneck. One innovative solution 
is the use of huge pages, which allocate memory in larger chunks, thereby reducing the number of TLB entries required 
and potentially enhancing overall system performance. Advancements in hardware-level security, such as CHERI's 
capability-based addressing, offer additional performance enhancement opportunities by tightly controlling memory 
access and accelerating memory management operations. Integrating huge pages into memory management strategies 
alongside CHERI's capability-based addressing can optimize TLB utilization and leverage security features for 
significant performance improvements.
\newline
% The future work section outlines the planned research timeline, focusing on the development and evaluation of FAT-pointer-based 
% range addresses. Key milestones include the initial development phase in July 2024, followed by integration with the RISC-V architecture 
% from August to September 2024. Detailed testing and evaluation are scheduled from October 2024 to February 2025, with an extension 
% of the implementation to uni-kernels planned from March to May 2025. Finalization and optimization of the approach are expected 
% from June to September 2025, culminating in a comprehensive evaluation and documentation of the results from January to September 2026.
% \newline

This paper aims to demonstrate how leveraging physically contiguous memory and advanced security architectures like CHERI can 
enhance memory management efficiency while ensuring robust security measures. These advancements ultimately contribute to 
improved system performance, addressing the challenges posed by the increasing complexity and size of modern application workloads.

\bibliographystyle{ACM-Reference-Format}
\bibliography{paperReferences}

% \section{Template Overview}
% As noted in the introduction, the ``\verb|acmart|'' document class can
% be used to prepare many different kinds of documentation --- a
% double-anonymous initial submission of a full-length technical paper, a
% two-page SIGGRAPH Emerging Technologies abstract, a ``camera-ready''
% journal article, a SIGCHI Extended Abstract, and more --- all by
% selecting the appropriate {\itshape template style} and {\itshape
%   template parameters}.

% This document will explain the major features of the document
% class. For further information, the {\itshape \LaTeX\ User's Guide} is
% available from
% \url{https://www.acm.org/publications/proceedings-template}.

% \subsection{Template Styles}

% The primary parameter given to the ``\verb|acmart|'' document class is
% the {\itshape template style} which corresponds to the kind of publication
% or SIG publishing the work. This parameter is enclosed in square
% brackets and is a part of the {\verb|documentclass|} command:
% \begin{verbatim}
%   \documentclass[STYLE]{acmart}
% \end{verbatim}

% Journals use one of three template styles. All but three ACM journals
% use the {\verb|acmsmall|} template style:
% \begin{itemize}
% \item {\texttt{acmsmall}}: The default journal template style.
% \item {\texttt{acmlarge}}: Used by JOCCH and TAP.
% \item {\texttt{acmtog}}: Used by TOG.
% \end{itemize}

% The majority of conference proceedings documentation will use the {\verb|acmconf|} template style.
% \begin{itemize}
% \item {\texttt{sigconf}}: The default proceedings template style.
% \item{\texttt{sigchi}}: Used for SIGCHI conference articles.
% \item{\texttt{sigplan}}: Used for SIGPLAN conference articles.
% \end{itemize}

% \subsection{Template Parameters}

% In addition to specifying the {\itshape template style} to be used in
% formatting your work, there are a number of {\itshape template parameters}
% which modify some part of the applied template style. A complete list
% of these parameters can be found in the {\itshape \LaTeX\ User's Guide.}

% Frequently-used parameters, or combinations of parameters, include:
% \begin{itemize}
% \item {\texttt{anonymous,review}}: Suitable for a ``double-anonymous''
%   conference submission. Anonymizes the work and includes line
%   numbers. Use with the \texttt{\acmSubmissionID} command to print the
%   submission's unique ID on each page of the work.
% \item{\texttt{authorversion}}: Produces a version of the work suitable
%   for posting by the author.
% \item{\texttt{screen}}: Produces colored hyperlinks.
% \end{itemize}

% This document uses the following string as the first command in the
% source file:
% \begin{verbatim}
% \documentclass[sigconf,authordraft]{acmart}
% \end{verbatim}

% \section{Modifications}

% Modifying the template --- including but not limited to: adjusting
% margins, typeface sizes, line spacing, paragraph and list definitions,
% and the use of the \verb|\vspace| command to manually adjust the
% vertical spacing between elements of your work --- is not allowed.

% {\bfseries Your document will be returned to you for revision if
%   modifications are discovered.}

% \section{Typefaces}

% The ``\verb|acmart|'' document class requires the use of the
% ``Libertine'' typeface family. Your \TeX\ installation should include
% this set of packages. Please do not substitute other typefaces. The
% ``\verb|lmodern|'' and ``\verb|ltimes|'' packages should not be used,
% as they will override the built-in typeface families.

% \section{Title Information}

% The title of your work should use capital letters appropriately -
% \url{https://capitalizemytitle.com/} has useful rules for
% capitalization. Use the {\verb|title|} command to define the title of
% your work. If your work has a subtitle, define it with the
% {\verb|subtitle|} command.  Do not insert line breaks in your title.

% If your title is lengthy, you must define a short version to be used
% in the page headers, to prevent overlapping text. The \verb|title|
% command has a ``short title'' parameter:
% \begin{verbatim}
%   \title[short title]{full title}
% \end{verbatim}

% \section{Authors and Affiliations}

% Each author must be defined separately for accurate metadata
% identification.  As an exception, multiple authors may share one
% affiliation. Authors' names should not be abbreviated; use full first
% names wherever possible. Include authors' e-mail addresses whenever
% possible.

% Grouping authors' names or e-mail addresses, or providing an ``e-mail
% alias,'' as shown below, is not acceptable:
% \begin{verbatim}
%   \author{Brooke Aster, David Mehldau}
%   \email{dave,judy,steve@university.edu}
%   \email{firstname.lastname@phillips.org}
% \end{verbatim}

% The \verb|authornote| and \verb|authornotemark| commands allow a note
% to apply to multiple authors --- for example, if the first two authors
% of an article contributed equally to the work.

% If your author list is lengthy, you must define a shortened version of
% the list of authors to be used in the page headers, to prevent
% overlapping text. The following command should be placed just after
% the last \verb|\author{}| definition:
% \begin{verbatim}
%   \renewcommand{\shortauthors}{McCartney, et al.}
% \end{verbatim}
% Omitting this command will force the use of a concatenated list of all
% of the authors' names, which may result in overlapping text in the
% page headers.

% The article template's documentation, available at
% \url{https://www.acm.org/publications/proceedings-template}, has a
% complete explanation of these commands and tips for their effective
% use.

% Note that authors' addresses are mandatory for journal articles.

% \section{Rights Information}

% Authors of any work published by ACM will need to complete a rights
% form. Depending on the kind of work, and the rights management choice
% made by the author, this may be copyright transfer, permission,
% license, or an OA (open access) agreement.

% Regardless of the rights management choice, the author will receive a
% copy of the completed rights form once it has been submitted. This
% form contains \LaTeX\ commands that must be copied into the source
% document. When the document source is compiled, these commands and
% their parameters add formatted text to several areas of the final
% document:
% \begin{itemize}
% \item the ``ACM Reference Format'' text on the first page.
% \item the ``rights management'' text on the first page.
% \item the conference information in the page header(s).
% \end{itemize}

% Rights information is unique to the work; if you are preparing several
% works for an event, make sure to use the correct set of commands with
% each of the works.

% The ACM Reference Format text is required for all articles over one
% page in length, and is optional for one-page articles (abstracts).

% \section{CCS Concepts and User-Defined Keywords}

% Two elements of the ``acmart'' document class provide powerful
% taxonomic tools for you to help readers find your work in an online
% search.

% The ACM Computing Classification System ---
% \url{https://www.acm.org/publications/class-2012} --- is a set of
% classifiers and concepts that describe the computing
% discipline. Authors can select entries from this classification
% system, via \url{https://dl.acm.org/ccs/ccs.cfm}, and generate the
% commands to be included in the \LaTeX\ source.

% User-defined keywords are a comma-separated list of words and phrases
% of the authors' choosing, providing a more flexible way of describing
% the research being presented.

% CCS concepts and user-defined keywords are required for for all
% articles over two pages in length, and are optional for one- and
% two-page articles (or abstracts).

% \section{Sectioning Commands}

% Your work should use standard \LaTeX\ sectioning commands:
% \verb|section|, \verb|subsection|, \verb|subsubsection|, and
% \verb|paragraph|. They should be numbered; do not remove the numbering
% from the commands.

% Simulating a sectioning command by setting the first word or words of
% a paragraph in boldface or italicized text is {\bfseries not allowed.}

% \section{Tables}

% The ``\verb|acmart|'' document class includes the ``\verb|booktabs|''
% package --- \url{https://ctan.org/pkg/booktabs} --- for preparing
% high-quality tables.

% Table captions are placed {\itshape above} the table.

% Because tables cannot be split across pages, the best placement for
% them is typically the top of the page nearest their initial cite.  To
% ensure this proper ``floating'' placement of tables, use the
% environment \textbf{table} to enclose the table's contents and the
% table caption.  The contents of the table itself must go in the
% \textbf{tabular} environment, to be aligned properly in rows and
% columns, with the desired horizontal and vertical rules.  Again,
% detailed instructions on \textbf{tabular} material are found in the
% \textit{\LaTeX\ User's Guide}.

% Immediately following this sentence is the point at which
% Table~\ref{tab:freq} is included in the input file; compare the
% placement of the table here with the table in the printed output of
% this document.

% \begin{table}
%   \caption{Frequency of Special Characters}
%   \label{tab:freq}
%   \begin{tabular}{ccl}
%     \toprule
%     Non-English or Math&Frequency&Comments\\
%     \midrule
%     \O & 1 in 1,000& For Swedish names\\
%     $\pi$ & 1 in 5& Common in math\\
%     \$ & 4 in 5 & Used in business\\
%     $\Psi^2_1$ & 1 in 40,000& Unexplained usage\\
%   \bottomrule
% \end{tabular}
% \end{table}

% To set a wider table, which takes up the whole width of the page's
% live area, use the environment \textbf{table*} to enclose the table's
% contents and the table caption.  As with a single-column table, this
% wide table will ``float'' to a location deemed more
% desirable. Immediately following this sentence is the point at which
% Table~\ref{tab:commands} is included in the input file; again, it is
% instructive to compare the placement of the table here with the table
% in the printed output of this document.

% \begin{table*}
%   \caption{Some Typical Commands}
%   \label{tab:commands}
%   \begin{tabular}{ccl}
%     \toprule
%     Command &A Number & Comments\\
%     \midrule
%     \texttt{{\char'134}author} & 100& Author \\
%     \texttt{{\char'134}table}& 300 & For tables\\
%     \texttt{{\char'134}table*}& 400& For wider tables\\
%     \bottomrule
%   \end{tabular}
% \end{table*}

% Always use midrule to separate table header rows from data rows, and
% use it only for this purpose. This enables assistive technologies to
% recognise table headers and support their users in navigating tables
% more easily.

% \section{Math Equations}
% You may want to display math equations in three distinct styles:
% inline, numbered or non-numbered display.  Each of the three are
% discussed in the next sections.

% \subsection{Inline (In-text) Equations}
% A formula that appears in the running text is called an inline or
% in-text formula.  It is produced by the \textbf{math} environment,
% which can be invoked with the usual
% \texttt{{\char'134}begin\,\ldots{\char'134}end} construction or with
% the short form \texttt{\$\,\ldots\$}. You can use any of the symbols
% and structures, from $\alpha$ to $\omega$, available in
% \LaTeX~\cite{Lamport:LaTeX}; this section will simply show a few
% examples of in-text equations in context. Notice how this equation:
% \begin{math}
%   \lim_{n\rightarrow \infty}x=0
% \end{math},
% set here in in-line math style, looks slightly different when
% set in display style.  (See next section).

% \subsection{Display Equations}
% A numbered display equation---one set off by vertical space from the
% text and centered horizontally---is produced by the \textbf{equation}
% environment. An unnumbered display equation is produced by the
% \textbf{displaymath} environment.

% Again, in either environment, you can use any of the symbols and
% structures available in \LaTeX\@; this section will just give a couple
% of examples of display equations in context.  First, consider the
% equation, shown as an inline equation above:
% \begin{equation}
%   \lim_{n\rightarrow \infty}x=0
% \end{equation}
% Notice how it is formatted somewhat differently in
% the \textbf{displaymath}
% environment.  Now, we'll enter an unnumbered equation:
% \begin{displaymath}
%   \sum_{i=0}^{\infty} x + 1
% \end{displaymath}
% and follow it with another numbered equation:
% \begin{equation}
%   \sum_{i=0}^{\infty}x_i=\int_{0}^{\pi+2} f
% \end{equation}
% just to demonstrate \LaTeX's able handling of numbering.

% \section{Figures}

% The ``\verb|figure|'' environment should be used for figures. One or
% more images can be placed within a figure. If your figure contains
% third-party material, you must clearly identify it as such, as shown
% in the example below.
% % \begin{figure}[h]
% %   \centering
% %   \includegraphics[width=\linewidth]{sample-franklin}
% %   \caption{1907 Franklin Model D roadster. Photograph by Harris \&
% %     Ewing, Inc. [Public domain], via Wikimedia
% %     Commons. (\url{https://goo.gl/VLCRBB}).}
% %   \Description{A woman and a girl in white dresses sit in an open car.}
% % \end{figure}

% Your figures should contain a caption which describes the figure to
% the reader.

% Figure captions are placed {\itshape below} the figure.

% Every figure should also have a figure description unless it is purely
% decorative. These descriptions convey what’s in the image to someone
% who cannot see it. They are also used by search engine crawlers for
% indexing images, and when images cannot be loaded.

% A figure description must be unformatted plain text less than 2000
% characters long (including spaces).  {\bfseries Figure descriptions
%   should not repeat the figure caption – their purpose is to capture
%   important information that is not already provided in the caption or
%   the main text of the paper.} For figures that convey important and
% complex new information, a short text description may not be
% adequate. More complex alternative descriptions can be placed in an
% appendix and referenced in a short figure description. For example,
% provide a data table capturing the information in a bar chart, or a
% structured list representing a graph.  For additional information
% regarding how best to write figure descriptions and why doing this is
% so important, please see
% \url{https://www.acm.org/publications/taps/describing-figures/}.

% \subsection{The ``Teaser Figure''}

% A ``teaser figure'' is an image, or set of images in one figure, that
% are placed after all author and affiliation information, and before
% the body of the article, spanning the page. If you wish to have such a
% figure in your article, place the command immediately before the
% \verb|\maketitle| command:
% % \begin{verbatim}
% %   \begin{teaserfigure}
% %     \includegraphics[width=\textwidth]{sampleteaser}
% %     \caption{figure caption}
% %     \Description{figure description}
% %   \end{teaserfigure}
% % \end{verbatim}

% \section{Citations and Bibliographies}

% The use of \BibTeX\ for the preparation and formatting of one's
% references is strongly recommended. Authors' names should be complete
% --- use full first names (``Donald E. Knuth'') not initials
% (``D. E. Knuth'') --- and the salient identifying features of a
% reference should be included: title, year, volume, number, pages,
% article DOI, etc.

% The bibliography is included in your source document with these two
% commands, placed just before the \verb|\end{document}| command:
% \begin{verbatim}
%   \bibliographystyle{ACM-Reference-Format}
%   \bibliography{bibfile}
% \end{verbatim}
% where ``\verb|bibfile|'' is the name, without the ``\verb|.bib|''
% suffix, of the \BibTeX\ file.

% Citations and references are numbered by default. A small number of
% ACM publications have citations and references formatted in the
% ``author year'' style; for these exceptions, please include this
% command in the {\bfseries preamble} (before the command
% ``\verb|\begin{document}|'') of your \LaTeX\ source:
% \begin{verbatim}
%   \citestyle{acmauthoryear}
% \end{verbatim}


%   Some examples.  A paginated journal article \cite{Abril07}, an
%   enumerated journal article \cite{Cohen07}, a reference to an entire
%   issue \cite{JCohen96}, a monograph (whole book) \cite{Kosiur01}, a
%   monograph/whole book in a series (see 2a in spec. document)
%   \cite{Harel79}, a divisible-book such as an anthology or compilation
%   \cite{Editor00} followed by the same example, however we only output
%   the series if the volume number is given \cite{Editor00a} (so
%   Editor00a's series should NOT be present since it has no vol. no.),
%   a chapter in a divisible book \cite{Spector90}, a chapter in a
%   divisible book in a series \cite{Douglass98}, a multi-volume work as
%   book \cite{Knuth97}, a couple of articles in a proceedings (of a
%   conference, symposium, workshop for example) (paginated proceedings
%   article) \cite{Andler79, Hagerup1993}, a proceedings article with
%   all possible elements \cite{Smith10}, an example of an enumerated
%   proceedings article \cite{VanGundy07}, an informally published work
%   \cite{Harel78}, a couple of preprints \cite{Bornmann2019,
%     AnzarootPBM14}, a doctoral dissertation \cite{Clarkson85}, a
%   master's thesis: \cite{anisi03}, an online document / world wide web
%   resource \cite{Thornburg01, Ablamowicz07, Poker06}, a video game
%   (Case 1) \cite{Obama08} and (Case 2) \cite{Novak03} and \cite{Lee05}
%   and (Case 3) a patent \cite{JoeScientist001}, work accepted for
%   publication \cite{rous08}, 'YYYYb'-test for prolific author
%   \cite{SaeediMEJ10} and \cite{SaeediJETC10}. Other cites might
%   contain 'duplicate' DOI and URLs (some SIAM articles)
%   \cite{Kirschmer:2010:AEI:1958016.1958018}. Boris / Barbara Beeton:
%   multi-volume works as books \cite{MR781536} and \cite{MR781537}. A
%   couple of citations with DOIs:
%   \cite{2004:ITE:1009386.1010128,Kirschmer:2010:AEI:1958016.1958018}. Online
%   citations: \cite{TUGInstmem, Thornburg01, CTANacmart}.
%   Artifacts: \cite{R} and \cite{UMassCitations}.

% \section{Acknowledgments}

% Identification of funding sources and other support, and thanks to
% individuals and groups that assisted in the research and the
% preparation of the work should be included in an acknowledgment
% section, which is placed just before the reference section in your
% document.

% This section has a special environment:
% \begin{verbatim}
%   \begin{acks}
%   ...
%   \end{acks}
% \end{verbatim}
% so that the information contained therein can be more easily collected
% during the article metadata extraction phase, and to ensure
% consistency in the spelling of the section heading.

% Authors should not prepare this section as a numbered or unnumbered {\verb|\section|}; please use the ``{\verb|acks|}'' environment.

% \section{Appendices}

% If your work needs an appendix, add it before the
% ``\verb|\end{document}|'' command at the conclusion of your source
% document.

% Start the appendix with the ``\verb|appendix|'' command:
% \begin{verbatim}
%   \appendix
% \end{verbatim}
% and note that in the appendix, sections are lettered, not
% numbered. This document has two appendices, demonstrating the section
% and subsection identification method.

% \section{Multi-language papers}

% Papers may be written in languages other than English or include
% titles, subtitles, keywords and abstracts in different languages (as a
% rule, a paper in a language other than English should include an
% English title and an English abstract).  Use \verb|language=...| for
% every language used in the paper.  The last language indicated is the
% main language of the paper.  For example, a French paper with
% additional titles and abstracts in English and German may start with
% the following command
% \begin{verbatim}
% \documentclass[sigconf, language=english, language=german,
%                language=french]{acmart}
% \end{verbatim}

% The title, subtitle, keywords and abstract will be typeset in the main
% language of the paper.  The commands \verb|\translatedXXX|, \verb|XXX|
% begin title, subtitle and keywords, can be used to set these elements
% in the other languages.  The environment \verb|translatedabstract| is
% used to set the translation of the abstract.  These commands and
% environment have a mandatory first argument: the language of the
% second argument.  See \verb|sample-sigconf-i13n.tex| file for examples
% of their usage.

% \section{SIGCHI Extended Abstracts}

% The ``\verb|sigchi-a|'' template style (available only in \LaTeX\ and
% not in Word) produces a landscape-orientation formatted article, with
% a wide left margin. Three environments are available for use with the
% ``\verb|sigchi-a|'' template style, and produce formatted output in
% the margin:
% \begin{description}
% \item[\texttt{sidebar}:]  Place formatted text in the margin.
% \item[\texttt{marginfigure}:] Place a figure in the margin.
% \item[\texttt{margintable}:] Place a table in the margin.
% \end{description}

% %%
% %% The acknowledgments section is defined using the "acks" environment
% %% (and NOT an unnumbered section). This ensures the proper
% %% identification of the section in the article metadata, and the
% %% consistent spelling of the heading.
% \begin{acks}
% To Robert, for the bagels and explaining CMYK and color spaces.
% \end{acks}

% %%
% %% The next two lines define the bibliography style to be used, and
% %% the bibliography file.
% \bibliographystyle{ACM-Reference-Format}
% \bibliography{sample-base}


% %%
% %% If your work has an appendix, this is the place to put it.
% \appendix

% \section{Research Methods}

% \subsection{Part One}

% Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi
% malesuada, quam in pulvinar varius, metus nunc fermentum urna, id
% sollicitudin purus odio sit amet enim. Aliquam ullamcorper eu ipsum
% vel mollis. Curabitur quis dictum nisl. Phasellus vel semper risus, et
% lacinia dolor. Integer ultricies commodo sem nec semper.

% \subsection{Part Two}

% Etiam commodo feugiat nisl pulvinar pellentesque. Etiam auctor sodales
% ligula, non varius nibh pulvinar semper. Suspendisse nec lectus non
% ipsum convallis congue hendrerit vitae sapien. Donec at laoreet
% eros. Vivamus non purus placerat, scelerisque diam eu, cursus
% ante. Etiam aliquam tortor auctor efficitur mattis.

% \section{Online Resources}

% Nam id fermentum dui. Suspendisse sagittis tortor a nulla mollis, in
% pulvinar ex pretium. Sed interdum orci quis metus euismod, et sagittis
% enim maximus. Vestibulum gravida massa ut felis suscipit
% congue. Quisque mattis elit a risus ultrices commodo venenatis eget
% dui. Etiam sagittis eleifend elementum.

% Nam interdum magna at lectus dignissim, ac dignissim lorem
% rhoncus. Maecenas eu arcu ac neque placerat aliquam. Nunc pulvinar
% massa et mattis lacinia.

\end{document}
\endinput
%%
%% End of file `sample-sigconf-authordraft.tex'.

